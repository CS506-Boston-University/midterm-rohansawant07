{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"1fffe419-d983-4cbc-8947-b65ced8dcb9a","_uuid":"565d8357-5fd4-477d-b7b9-3d62dfce3b64","trusted":true},"source":["# CODE"]},{"cell_type":"code","execution_count":84,"metadata":{"_cell_guid":"710162be-6f06-4e88-b841-25b0055d0592","_uuid":"b2f336f7-55a0-4627-bde0-f3fe49d93f35","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\rohan\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\rohan\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.metrics import mean_squared_error, confusion_matrix\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["LOADING THE DATASET"]},{"cell_type":"code","execution_count":85,"metadata":{"_cell_guid":"e7936c74-cb44-4dd3-be9a-37fda37cca93","_uuid":"84ca3eed-dee2-4228-a4fe-8704a223732f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train.csv shape is  (139753, 9)\n","test.csv shape is  (13976, 2)\n"]}],"source":["train_data = pd.read_csv(r\"C:\\Users\\rohan\\Downloads\\DS_midterm\\train.csv\")\n","test_data = pd.read_csv(r\"C:\\Users\\rohan\\Downloads\\DS_midterm\\test.csv\")\n","\n","print(\"train.csv shape is \", train_data.shape)\n","print(\"test.csv shape is \", test_data.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":86,"metadata":{"_cell_guid":"449c8fea-25ef-4f51-a6ae-0cbf44feb183","_uuid":"82e0e2b8-ead8-4d91-836b-c6db7a607787","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["test_data= pd.merge(train_data, test_data, left_on='Id', right_on='Id')\n","test_data = test_data.drop(columns=['Score_x'])\n","test_data = test_data.rename(columns={'Score_y': 'Score'})"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"024ad60c-0748-4418-ac85-7d89d59dc85f","_uuid":"5247ef29-f40b-4d08-8bf3-a170f158c0b9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["test_data.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["PREPROCESSING"]},{"cell_type":"code","execution_count":87,"metadata":{"_cell_guid":"99f22e49-5592-475c-b83c-a6db501bc719","_uuid":"3ad55872-69ad-4200-871a-0ee7e693fdf3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def process(trainingSet,submissionSet,col = 'Text'):\n","    trainingSet['Helpfulness'] = trainingSet['HelpfulnessNumerator'] / trainingSet['HelpfulnessDenominator']\n","    trainingSet['Helpfulness'] = trainingSet['Helpfulness'].fillna(0)\n","    \n","    training_helpful = trainingSet[(trainingSet['HelpfulnessNumerator']<=trainingSet['HelpfulnessDenominator'])]\n","    training_drop = training_helpful.dropna()\n","    print(\"train set after cleaning wrong in helpfulness:   \" , trainingSet.shape)\n","    print(\"train set after drop NaN:   \",training_drop.shape)\n","\n","    X_train, X_test, Y_train, Y_test = train_test_split(\n","        training_drop.drop(['Score'], axis=1),\n","        training_drop['Score'],\n","        test_size=1/4.0,\n","        random_state=0\n","    )\n","\n","\n","    if col == 'Text':\n","        drop_col = ['Id', 'ProductId', 'UserId', 'Summary', 'Time']\n","    elif col == 'Summary':\n","        drop_col = ['Id', 'ProductId', 'UserId', 'Text', 'Time']\n","\n","    X_train_processed = X_train.drop(columns = drop_col)\n","    X_test_processed = X_test.drop(columns = drop_col)\n","    submission_processed = submissionSet.drop(columns = drop_col)\n","    print(\"train set shape:  \",X_train_processed.shape,\"test set shape:  \",X_test_processed.shape)\n","    \n","    return X_train_processed,X_test_processed,Y_train,Y_test,submission_processed"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["CLEANING THE DATASET"]},{"cell_type":"code","execution_count":88,"metadata":{"_cell_guid":"43854920-0630-4d40-b220-0b8edb7a6259","_uuid":"29e2399f-277c-4f54-9677-7a14bbb6695c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#clean the text\n","\n","def remove_char(x):\n","    special = '[^A-Za-z ]+'\n","    x = re.sub(special,'',x)\n","    x = x.strip()\n","    x = x.lower()\n","    return x\n","\n","\n","def clean_word(dataset,col):\n","    stop_words = set(stopwords.words('english'))\n","    test = dataset[col].apply(lambda row: remove_char(str(row))).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n","    return test"]},{"cell_type":"code","execution_count":89,"metadata":{"_cell_guid":"b042076b-83de-4fdb-88f3-b06558ffe5d2","_uuid":"af664a45-9f89-479a-8bac-d44bfb37e129","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["train_data['Text'] = train_data['Text'] + ' ' + train_data['Summary']\n","test_data['Text'] = test_data['Text']  + ' ' + test_data['Summary']"]},{"cell_type":"code","execution_count":90,"metadata":{"_cell_guid":"e8bdb141-21f7-45c8-89a4-481e3d0aff8b","_uuid":"77e22a14-258a-4109-9a45-7e80c9dcd08b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train set after cleaning wrong in helpfulness:    (139753, 10)\n","train set after drop NaN:    (125774, 10)\n","train set shape:   (94330, 4) test set shape:   (31444, 4)\n"]}],"source":["#SEPERATE THE DATASET \n","X_train_processed,X_test_processed,Y_train,Y_test,submission_processed = process(train_data,test_data,'Text')"]},{"cell_type":"code","execution_count":91,"metadata":{"_cell_guid":"fef84e6f-350b-43be-be02-adda6ece10aa","_uuid":"8407be4d-b176-4662-982e-f0d321fde635","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HelpfulnessNumerator</th>\n","      <th>HelpfulnessDenominator</th>\n","      <th>Text</th>\n","      <th>Helpfulness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>85931</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>christian movies of what is to become in our w...</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>100573</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>Leave it to director John Frankenheimer to mak...</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>17624</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>My grands just loved the 3D version. The 3D ve...</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>30520</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>But it SUCKED!  OK, it started out really cool...</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8247</th>\n","      <td>146</td>\n","      <td>151</td>\n","      <td>This delightful trilogy tells the story of Eli...</td>\n","      <td>0.966887</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        HelpfulnessNumerator  HelpfulnessDenominator  \\\n","85931                      0                       0   \n","100573                     2                       2   \n","17624                      1                       2   \n","30520                      0                       0   \n","8247                     146                     151   \n","\n","                                                     Text  Helpfulness  \n","85931   christian movies of what is to become in our w...     0.000000  \n","100573  Leave it to director John Frankenheimer to mak...     1.000000  \n","17624   My grands just loved the 3D version. The 3D ve...     0.500000  \n","30520   But it SUCKED!  OK, it started out really cool...     0.000000  \n","8247    This delightful trilogy tells the story of Eli...     0.966887  "]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["X_train_processed.head()"]},{"cell_type":"code","execution_count":92,"metadata":{"_cell_guid":"b2044257-de9f-4f99-91db-b1b6b6f5ae94","_uuid":"fe1023c6-1255-4e2d-a2f5-4ac03498eb6c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["85931     christian movies become world today would save...\n","100573    leave director john frankenheimer make movie t...\n","17624     grands loved version versions movies order cle...\n","30520     sucked ok started really cool group like frien...\n","8247      delightful trilogy tells story elisabeth bavar...\n","Name: Text, dtype: object"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["# APLLY THE CLEANNING FUNCTION TO DATAFRAME\n","X_train_text = clean_word(X_train_processed,'Text')\n","X_test_text = clean_word(X_test_processed,'Text')\n","submission_text = clean_word(submission_processed,'Text')\n","X_train_text.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["USING TF-IDF TO VECTORIZE THE TEXT COLUMN"]},{"cell_type":"code","execution_count":93,"metadata":{"_cell_guid":"c49dfbb6-d1c7-4824-ac7d-b773d1cc09d4","_uuid":"7332f59f-f8e9-42f8-b216-e0c571cdb3b2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of training set CountVector&text:  (94330, 317101)\n"]}],"source":["#countVector the data\n","vectorizer_text = CountVectorizer()\n","X_training_vector_text = vectorizer_text.fit_transform(X_train_text)\n","X_test_vectorr_text = vectorizer_text.transform(X_test_text)\n","submission_vectorr_text = vectorizer_text.transform(submission_text)\n","print(\"shape of training set CountVector&text: \",X_training_vector_text.shape)"]},{"cell_type":"code","execution_count":94,"metadata":{"_cell_guid":"e2ef3f45-7ee6-478d-ac5d-1730baae3411","_uuid":"b4a55844-f39a-453a-aea0-81d9f5384a96","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of training set TFIDF&text:  (94330, 317101)\n"]}],"source":["#tfidf the data\n","tfidf_text = TfidfVectorizer()\n","X_training_tfidf_text = tfidf_text.fit_transform(X_train_text)\n","X_test_tfidf_text = tfidf_text.transform(X_test_text)\n","submission_tfidf_text = tfidf_text.transform(submission_text)\n","print(\"shape of training set TFIDF&text: \",X_training_tfidf_text.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8303a3bf-c6f5-41a3-ba8d-e4cf7cb93162","_uuid":"f11edefb-c226-4f16-84e7-1dce38f97080","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","clf7 = LogisticRegression(random_state=0,C=80).fit(X_training_tfidf_text,Y_train)\n","logprevec7 = clf7.predict(X_test_tfidf_text)\n","print(\"RMSE on testing set = \", mean_squared_error(Y_test, logprevec7))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["SELCTING A MODEL AND TUNING ITS PARAMETERS"]},{"cell_type":"code","execution_count":100,"metadata":{"_cell_guid":"41745943-42bc-4758-9989-952fa9ed3a96","_uuid":"a1f81607-d1de-44df-bb40-1193453e017c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE on testing set =  0.6991291067764173\n","R^2 score on testing set =  0.50157853724913\n"]}],"source":["from sklearn import linear_model\n","from sklearn.metrics import mean_squared_error, r2_score\n","model = linear_model.Ridge(alpha=3.0).fit(X_training_tfidf_text,Y_train)\n","logprevec9= model.predict(X_test_tfidf_text)\n","print(\"RMSE on testing set = \", mean_squared_error(Y_test, logprevec9))\n","#print accuracy\n","#print(\"Accuracy on testing set = \", accuracy_score(Y_test, model.predict(X_test_tfidf_text)))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["TESTING THE MODEL ON THE TEST SET AND SAVING TO A CSV FILE"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["submission_predict = test_data\n","submission_predict['Score'] = model.predict(submission_tfidf_text)\n","\n","submission_output = submission_predict[['Id','Score']]\n","submission_output.to_csv(r\"C:\\Users\\rohan\\Downloads\\DS_midterm\\submission.csv\",index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7486b54c-d7d7-40a3-8832-933189aa7c75","_uuid":"65fcd126-f9a5-44d3-912e-ee110ba1d420","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","submission_predict = test_data"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
